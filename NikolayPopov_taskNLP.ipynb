{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Постановка задачи и мотивация\n",
    "\n",
    "Необходимо разработать инструмент для группировки идентичных наименований товаров\n",
    "\n",
    "Обычно такие инструменты используют для поддержания базы товаров в надлежащем виде:\n",
    "много товаров при постановке на учет имеют немного измененные названия (например в зависимости от поставщика), а для точного учета дубликаты в базе недопустимы\n",
    "\n",
    "Как правило у клиентов уже есть первичная база с эталонными названиями для существующих продуктов, если же их нет, то первым делом нужно собрать подобный список названий.\n",
    "\n",
    "Далее при поступлении новых товаров, производится поиск в базе эталонов и в полу-автоматическом режиме выбирается соответствует ли товар какому-то из эталонов, или это новый уникальный товар и должен пополнить список эталонных названий\n",
    "\n",
    "В нашем случае списка эталонных названий нет, т.е. задачу необходимо разбить на две логических части:\n",
    "<ul>\n",
    "<li>составление списка эталонных названий</li>\n",
    "<li>разработка инструмента для поиска совпадений с заданным списком эталонов</li>\n",
    "</ul>\n",
    "\n",
    "как правило данные списки довольно большие, поэтому будем пытаться разработать алгоритм работающий батчами и параллельно\n",
    "\n",
    "обычно в названиях бывают различные сокращения / опечатки , поэтому нужно строить алгоритм устойчивый к такого рода вещам\n",
    "\n",
    "### поиск совпадения с эталонами\n",
    "т.к. в списке эталонов не должно быть дубликатов, нет необходимости реализовывать алгоритмы кластеризации, достаточно реализовать поиск k-ближайших соседей с отсечением по порогу по метрике близости.\n",
    "\n",
    "Дополнительно стоит отметить, что в такой базе разные производители, граммовки, страна производства, год сбора урожая (для вина) и т.п. являются критическими факторами, но при этом они не всегда указываются поставщиком товаров в магазин\n",
    "\n",
    "\n",
    "### составление списка эталонов\n",
    "Для упрощения составления списка эталонных названий может использоваться тот же алгоритм, который предназначен для поиска совпадений с эталонами\n",
    "\n",
    "В любом случае данная процедура должна иметь человеческий контроль\n",
    "\n",
    "Для лучшего качества, необходимо итеративно провести процесс, до тех пор, пока не будет дальнейших изменений списка эталонов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dolgop/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from itertools import chain\n",
    "from transliterate import translit, exceptions\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from functools import lru_cache\n",
    "from sklearn.base import TransformerMixin, ClassifierMixin\n",
    "import sparse_dot_topn.sparse_dot_topn as ct\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "import numpy as np\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import pymorphy2\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_task_NLP.json') as f:\n",
    "    texts_clustered = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(chain(*texts_clustered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разведочный анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3580, 1223)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts), len(texts_clustered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  страна производитель иногда пишется, а иногда нет\n",
    "стоит экстрактировать страну, в отдельный признак (и собирать данные соответствующим способом в будущем)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Блинчики с мясом, Уже Готово , 140 г',\n",
       " 'Блинчики с мясом, Уже Готово , 220 г, Россия')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[3], texts[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "видна так же проблема с одним и тем же товаром в разных объемах/ разных годов и тп, т.е. стоит обрабатывать цифры в особом порядке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### названия иногда на английском языке, а иногда транслитом на русском\n",
    "стоит все перевести на русский язык\n",
    "\n",
    "аналогично производитель иногда пишется иногда нет, стоит выносить его в отдельный признак, и собирать новые данные уже с учетом этого"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Пицца Ристоранте специальная , Dr.Oetker, 330 г',\n",
       " 'Пицца Dr.Oetker Ristorante Специале 330г')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[-1000], texts[-999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# перейдем к разработке алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# дополнительные разделители для номеров и размерностей\n",
    "XN_LIST = [u'X', u'x', u'Х', u'х', u'н', u'N', u'n', u'H']\n",
    "STOP_LIST = ['-', 'X', 'x', 'Х', 'х', 'N', '.', ',', ';', '\"', \"'\", ':', '/',\n",
    "             '\\\\', '(', ')', '[', ']', '{', '}', '~', '_', '!', '...', '!!', '!!!']\n",
    "\n",
    "MORPHER = pymorphy2.MorphAnalyzer()\n",
    "CPU = cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(string, n=3):\n",
    "    '''\n",
    "    функция приводит строку к нижнему регистру и\n",
    "    разбивает её на символьные n-граммы\n",
    "\n",
    "    string - строка (название лекарства после предобработки)\n",
    "    n - число букв в n-грамме\n",
    "    '''\n",
    "    string = string.lower()\n",
    "    ngrams = zip(*[string[i:] for i in range(n)])\n",
    "    return [''.join(ngram) for ngram in ngrams]\n",
    "\n",
    "def batcher(df, size):\n",
    "    return (df.iloc[pos:pos + size] for pos in range(0, df.shape[0], size))\n",
    "\n",
    "def numbers_closeness(numbers_1, numbers_2, lam=2):\n",
    "    numbers_1 = numbers_1.split(';')\n",
    "    numbers_2 = numbers_2.split(';')\n",
    "    counts_1 = Counter(numbers_1)\n",
    "    counts_2 = Counter(numbers_2)\n",
    "    common = set(numbers_1) & set(numbers_2)\n",
    "    inter = 0\n",
    "    for number in common:\n",
    "        inter += min(counts_1[number], counts_2[number])\n",
    "    uni = len(numbers_1) + len(numbers_2) - inter\n",
    "    return ((inter + lam) * 1. / (uni + lam))\n",
    "\n",
    "\n",
    "def extract_numbers(text):\n",
    "    numbers = []\n",
    "    for token in text.split():\n",
    "        try:\n",
    "            float(token.replace(',','.'))\n",
    "            token = token.replace(',','.')\n",
    "            numbers.append(token)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return ';'.join(numbers)\n",
    "\n",
    "def top_k(match_sparse, row_number, k=3):\n",
    "    row = match_sparse[row_number]\n",
    "    ix = row.data.argsort()[-k:][::-1]\n",
    "    top_k_indicies = row.indices[ix]\n",
    "    top_k_values = row.data[ix]\n",
    "    return top_k_indicies, top_k_values\n",
    "\n",
    "\n",
    "def top_n_idx_sparse(matrix, n):\n",
    "    result_list = []\n",
    "    count = 0\n",
    "    for le, ri in (zip(matrix.indptr[:-1], matrix.indptr[1:])):\n",
    "        n_row_pick = min(n, ri - le)\n",
    "        ix = le + np.argsort(matrix.data[le:ri])[-n_row_pick:]\n",
    "        result_list.append(\n",
    "            np.concatenate([[matrix.indices[ix]],\n",
    "                            [matrix.data[ix]],\n",
    "                            [np.arange(n_row_pick)],\n",
    "                            [np.ones(shape=(n_row_pick,))*count]\n",
    "                           ], axis=0).T\n",
    "        )\n",
    "        count += 1\n",
    "    return np.concatenate(result_list)\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def parse_token(token):\n",
    "    return MORPHER.parse(token)[0].normal_form\n",
    "\n",
    "\n",
    "class NameCleanTransformer(TransformerMixin):\n",
    "    def __init__(self, njobs=CPU):\n",
    "        self.njobs=njobs\n",
    "\n",
    "    @staticmethod\n",
    "    def do_morphy(text):\n",
    "        new_text = []\n",
    "        for token in nltk.word_tokenize(text):\n",
    "            new_text.append(parse_token(token))\n",
    "        return ' '.join(new_text)\n",
    "\n",
    "    @staticmethod\n",
    "    def translit_text(x, lang='ru'):\n",
    "        tokens = nltk.word_tokenize(x)\n",
    "        final_text = \"\"\n",
    "        for tok in tokens:\n",
    "            try:\n",
    "                tr = translit(tok, lang)\n",
    "                final_text += tr + u' '\n",
    "            except exceptions.LanguageDetectionError:\n",
    "                final_text += tok + u' '\n",
    "        return final_text\n",
    "\n",
    "    @staticmethod\n",
    "    def nan_to_empty(x):\n",
    "        if (pd.isnull(x)) | (x == \"-\") | (x == \"_\"):\n",
    "            return ''\n",
    "        else:\n",
    "            return x.lower()\n",
    "\n",
    "    @staticmethod\n",
    "    def preprocess_name(names, split_rule=r'(\\d+[,|.]?\\d+|\\d+|\\/|\\+|!|№|\\.|,|\\(|\\)|%|\\*|~|\"|_)'):\n",
    "        '''\n",
    "        функия предобработки названий\n",
    "        на выходе - отсортированный лексикографически лист из токенов\n",
    "\n",
    "        names - названия\n",
    "        '''\n",
    "        ext_name_clean = []\n",
    "        for string in names:\n",
    "            res = []\n",
    "            for part in string.split():\n",
    "                results = re.split(split_rule, part)\n",
    "                results = list(filter(None, results))\n",
    "                results = NameCleanTransformer.split_dashes(results)\n",
    "                res.extend(results)\n",
    "            res = NameCleanTransformer.split_NX(res)\n",
    "            res = [w for w in res if w not in STOP_LIST]\n",
    "            res = sorted(res)\n",
    "            ext_name_clean.append(' '.join(res))\n",
    "        return pd.Series(ext_name_clean)\n",
    "\n",
    "    @staticmethod\n",
    "    def split_dashes(results):\n",
    "        '''\n",
    "        функция обработки дефисов\n",
    "        если дефис в середине, то не разрываем название\n",
    "        если дефис по краям, отделяем его\n",
    "\n",
    "        results - list, части названия\n",
    "        '''\n",
    "        results_clean = []\n",
    "        for r in results:\n",
    "            l_dash = False\n",
    "            if len(r) > 1:\n",
    "                if r[0] == '-':\n",
    "                    results_clean.append('-')\n",
    "                    r = r[1:]\n",
    "                if r[-1] == '-':\n",
    "                    r = r[:-1]\n",
    "                    l_dash = True\n",
    "                results_clean.append(r)\n",
    "                if l_dash:\n",
    "                    results_clean.append('-')\n",
    "            else:\n",
    "                results_clean.append(r)\n",
    "        return results_clean\n",
    "\n",
    "    @staticmethod\n",
    "    def split_NX(results, rule=r'(Х|х|X|x|N|n|Н)'):\n",
    "        '''\n",
    "        функция разбиения названия\n",
    "        цифры отделяются от слов, применяются разделители\n",
    "\n",
    "        results - list, части названия\n",
    "        '''\n",
    "        results_clean = []\n",
    "        if len(results) == 1:\n",
    "            return results\n",
    "        for idx in range(len(results)):\n",
    "            r = results[idx]\n",
    "            if not len(set(XN_LIST) & set(r)) > 0:\n",
    "                results_clean.append(r)\n",
    "\n",
    "            else:\n",
    "                if idx == 0:\n",
    "                    if any(i.isdigit() for i in results[idx + 1]) and r[-1] in rule:\n",
    "                        r = re.split(rule, r)\n",
    "                        r = list(filter(None, r))\n",
    "\n",
    "                elif idx == len(results) - 1:\n",
    "                    if any(i.isdigit() for i in results[idx - 1]) and r[0] in rule:\n",
    "                        r = re.split(rule, r)\n",
    "                        r = list(filter(None, r))\n",
    "\n",
    "                else:\n",
    "                    if any(i.isdigit() for i in results[idx + 1]) and r[-1] in rule or \\\n",
    "                                    any(i.isdigit() for i in results[idx - 1]) and r[0] in rule:\n",
    "                        r = re.split(rule, r)\n",
    "                        r = list(filter(None, r))\n",
    "\n",
    "                if isinstance(r, list):\n",
    "                    results_clean.extend(r)\n",
    "                else:\n",
    "                    results_clean.append(r)\n",
    "        return results_clean\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def make_transform(X):\n",
    "        X_new = NameCleanTransformer.preprocess_name(X)\n",
    "        X_new = X_new.apply(lambda x: NameCleanTransformer.translit_text(x.lower()))\n",
    "        X_new = X_new.apply(NameCleanTransformer.do_morphy)\n",
    "        return X_new\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        if self.njobs > 1:\n",
    "            data_split = np.array_split(X, self.njobs)\n",
    "            pool = Pool(self.njobs)\n",
    "            X_new = pd.concat(pool.map(NameCleanTransformer.make_transform, data_split))\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "        else:\n",
    "            X_new = NameCleanTransformer.make_transform(np.array(X))\n",
    "        return X_new\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        if self.njobs > 1:\n",
    "            data_split = np.array_split(X, self.njobs)\n",
    "            pool = Pool(self.njobs)\n",
    "            X_new = pd.concat(pool.map(NameCleanTransformer.make_transform, data_split))\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "        else:\n",
    "            X_new = NameCleanTransformer.make_transform(np.array(X))\n",
    "        return X_new\n",
    "\n",
    "\n",
    "class CandidatesSelector(ClassifierMixin):\n",
    "    def __init__(self, n_jobs=CPU, n_top=1000, lower_bound=0.1, batch_size=50000):\n",
    "        self.n_top = n_top\n",
    "        self.n_jobs = n_jobs\n",
    "        self.lower_bound = lower_bound\n",
    "        self.batch_size = batch_size\n",
    "        pass\n",
    "\n",
    "    def fit(self, B, y=None, **fit_params):\n",
    "        self.B = B.T.tocsr()\n",
    "\n",
    "    def find_top_n(self, A):\n",
    "        M, _ = A.shape\n",
    "        idx_dtype = np.int32\n",
    "        indptr = np.zeros(M + 1, dtype=idx_dtype)\n",
    "        nnz_max = M * self.n_top\n",
    "        indices = np.zeros(nnz_max, dtype=idx_dtype)\n",
    "        data = np.zeros(nnz_max, dtype=A.dtype)\n",
    "        _, N = self.B.shape\n",
    "\n",
    "        ct.sparse_dot_topn(\n",
    "            M, N, np.asarray(A.indptr, dtype=idx_dtype),\n",
    "            np.asarray(A.indices, dtype=idx_dtype),\n",
    "            A.data,\n",
    "            np.asarray(self.B.indptr, dtype=idx_dtype),\n",
    "            np.asarray(self.B.indices, dtype=idx_dtype),\n",
    "            self.B.data,\n",
    "            self.n_top,\n",
    "            self.lower_bound,\n",
    "            indptr, indices, data)\n",
    "        return csr_matrix((data, indices, indptr), shape=(M, N))\n",
    "\n",
    "    def predict(self, A):\n",
    "        A = A.tocsr()\n",
    "        ixs = [int(i) for i in np.linspace(0, A.shape[0], int(np.ceil(A.shape[0] / self.batch_size)+1))]\n",
    "        iter_num = 0\n",
    "        results = []\n",
    "        while iter_num*self.n_jobs < len(ixs)-1:\n",
    "            A_parts = [A[ixs[i]:ixs[i+1]] for i in range(\n",
    "                                                    iter_num*self.n_jobs,\n",
    "                                                    min(iter_num*self.n_jobs+self.n_jobs,\n",
    "                                                    len(ixs)-1)\n",
    "                                                    )]\n",
    "            if self.n_jobs > 1:\n",
    "                p = Pool(self.n_jobs)\n",
    "                result = (p.map(self.find_top_n, A_parts))\n",
    "                p.close()\n",
    "                p.join()\n",
    "            else:\n",
    "                result = [self.find_top_n(A_i) for A_i in A_parts]\n",
    "            result = vstack(result)\n",
    "            results.append(result)\n",
    "            iter_num += 1\n",
    "        return vstack(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_final_dataframe(match_sparse, etalons, candidates, k):\n",
    "    results = top_n_idx_sparse(match_sparse, n=k)\n",
    "    d = {'CANDIDATE_NAME':               candidates.iloc[results[:, 3]]['CANDIDATE_NAME'].values,\n",
    "         'ETALON_NAME':                  etalons.iloc[results[:, 0]]['ETALON_NAME'].values,\n",
    "         'SIMILARITY_SCORE':             results[:, 1],\n",
    "         'RANK':                         results[:, 2],\n",
    "         'ETALON_ID':                    etalons.iloc[results[:, 0]]['ETALON_ID'].values,\n",
    "         'CANDIDATE_ID':                 candidates.iloc[results[:, 3]]['CANDIDATE_ID'].values}\n",
    "    final_top = pd.DataFrame(d)\n",
    "    cand_digits = NameCleanTransformer.preprocess_name(final_top['CANDIDATE_NAME']).apply(extract_numbers)\n",
    "    etalon_digits = NameCleanTransformer.preprocess_name(final_top['ETALON_NAME']).apply(extract_numbers)\n",
    "    final_top['SIMILARITY_SCORE'] = final_top['SIMILARITY_SCORE'] * np.array([numbers_closeness(candidate_numbers, etalon_numbers) for candidate_numbers, etalon_numbers in zip(cand_digits, etalon_digits)])\n",
    "    final_top.sort_values(by=['CANDIDATE_ID', 'SIMILARITY_SCORE'], ascending=[True, False], inplace=True)\n",
    "    final_top.reset_index(drop=True, inplace=True)\n",
    "    final_top['RANK'] = np.concatenate(final_top.groupby(['CANDIDATE_ID']).SIMILARITY_SCORE.apply(lambda x: x.values.argsort()[::-1]+1).values)\n",
    "    return final_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# затестим что получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "NUM_NEIGHBOURS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "etalons = pd.DataFrame()\n",
    "etalons['ETALON_NAME'] = texts\n",
    "etalons['ETALON_ID'] = np.arange(len(etalons))\n",
    "\n",
    "candidates = pd.DataFrame()\n",
    "candidates['CANDIDATE_NAME'] = texts\n",
    "candidates['CANDIDATE_ID'] = np.arange(len(candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5572464466094971\n"
     ]
    }
   ],
   "source": [
    "names_selector = Pipeline([\n",
    "    ('transformer', NameCleanTransformer(\n",
    "                              njobs=CPU)),\n",
    "    ('tfidf', TfidfVectorizer(analyzer=ngrams)),\n",
    "    ('CandidatesSelector', CandidatesSelector(\n",
    "                              n_jobs=CPU,\n",
    "                              batch_size=BATCH_SIZE)\n",
    "                            )])\n",
    "t = time.time()\n",
    "names_selector.fit(etalons['ETALON_NAME'])\n",
    "print(time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names selector finished 1.0653631687164307\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "match_sparse = names_selector.predict(candidates['CANDIDATE_NAME'])\n",
    "print('names selector finished', time.time() - t)\n",
    "t = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_top_full = make_final_dataframe(match_sparse, etalons, candidates, NUM_NEIGHBOURS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим сравнения эталона с самим собой\n",
    "final_top_full = final_top_full[final_top_full['ETALON_ID']!=\n",
    "              final_top_full['CANDIDATE_ID']].sort_values(by='SIMILARITY_SCORE', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CANDIDATE_NAME</th>\n",
       "      <th>ETALON_NAME</th>\n",
       "      <th>SIMILARITY_SCORE</th>\n",
       "      <th>RANK</th>\n",
       "      <th>ETALON_ID</th>\n",
       "      <th>CANDIDATE_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8023</th>\n",
       "      <td>Биойогурт Данон Активиа питьевой чернослив с б...</td>\n",
       "      <td>Биойогурт Данон Активиа питьевой чернослив с б...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>800</td>\n",
       "      <td>803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7994</th>\n",
       "      <td>Биойогурт Данон Активиа питьевой чернослив с б...</td>\n",
       "      <td>Биойогурт Данон Активиа питьевой чернослив с б...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>803</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8803</th>\n",
       "      <td>Биопродукт Данон Активиа кефирный c бифидобакт...</td>\n",
       "      <td>Биопродукт Данон Активиа кефирный c бифидобакт...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>882</td>\n",
       "      <td>881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31451</th>\n",
       "      <td>Сыр Galbani Моцарелла Мини из коров мол 45% жи...</td>\n",
       "      <td>Сыр Galbani Моцарелла Мини из коров мол 45% жи...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>3146</td>\n",
       "      <td>3147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31641</th>\n",
       "      <td>Сыр Ламбер из коровьего молока 50% жирн 230г Р...</td>\n",
       "      <td>Сыр Ламбер из коровьего молока 50% жирн 230г Р...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>3168</td>\n",
       "      <td>3166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124</th>\n",
       "      <td>Зубная паста Colgate Бережное отбеливание 100 мл</td>\n",
       "      <td>Зубная паста Colgateт бережное отбеливание 100мл</td>\n",
       "      <td>0.900053</td>\n",
       "      <td>5</td>\n",
       "      <td>410</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4094</th>\n",
       "      <td>Зубная паста Бережное отбеливание Colgate, 100 мл</td>\n",
       "      <td>Зубная паста Colgateт бережное отбеливание 100мл</td>\n",
       "      <td>0.900053</td>\n",
       "      <td>5</td>\n",
       "      <td>410</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144</th>\n",
       "      <td>Зубная паста Colgate Бережное отбеливание, 100мл</td>\n",
       "      <td>Зубная паста Colgateт бережное отбеливание 100мл</td>\n",
       "      <td>0.900053</td>\n",
       "      <td>5</td>\n",
       "      <td>410</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29332</th>\n",
       "      <td>Сок Fleur Alpine яблоко осветленное с 4 мес ор...</td>\n",
       "      <td>Сок Fleur Alpine груша осветленная с 4 мес орг...</td>\n",
       "      <td>0.900020</td>\n",
       "      <td>2</td>\n",
       "      <td>2933</td>\n",
       "      <td>2935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29312</th>\n",
       "      <td>Сок Fleur Alpine груша осветленная с 4 мес орг...</td>\n",
       "      <td>Сок Fleur Alpine яблоко осветленное с 4 мес ор...</td>\n",
       "      <td>0.900020</td>\n",
       "      <td>2</td>\n",
       "      <td>2935</td>\n",
       "      <td>2933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1154 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          CANDIDATE_NAME  \\\n",
       "8023   Биойогурт Данон Активиа питьевой чернослив с б...   \n",
       "7994   Биойогурт Данон Активиа питьевой чернослив с б...   \n",
       "8803   Биопродукт Данон Активиа кефирный c бифидобакт...   \n",
       "31451  Сыр Galbani Моцарелла Мини из коров мол 45% жи...   \n",
       "31641  Сыр Ламбер из коровьего молока 50% жирн 230г Р...   \n",
       "...                                                  ...   \n",
       "4124    Зубная паста Colgate Бережное отбеливание 100 мл   \n",
       "4094   Зубная паста Бережное отбеливание Colgate, 100 мл   \n",
       "4144    Зубная паста Colgate Бережное отбеливание, 100мл   \n",
       "29332  Сок Fleur Alpine яблоко осветленное с 4 мес ор...   \n",
       "29312  Сок Fleur Alpine груша осветленная с 4 мес орг...   \n",
       "\n",
       "                                             ETALON_NAME  SIMILARITY_SCORE  \\\n",
       "8023   Биойогурт Данон Активиа питьевой чернослив с б...          1.000000   \n",
       "7994   Биойогурт Данон Активиа питьевой чернослив с б...          1.000000   \n",
       "8803   Биопродукт Данон Активиа кефирный c бифидобакт...          1.000000   \n",
       "31451  Сыр Galbani Моцарелла Мини из коров мол 45% жи...          1.000000   \n",
       "31641  Сыр Ламбер из коровьего молока 50% жирн 230г Р...          1.000000   \n",
       "...                                                  ...               ...   \n",
       "4124    Зубная паста Colgateт бережное отбеливание 100мл          0.900053   \n",
       "4094    Зубная паста Colgateт бережное отбеливание 100мл          0.900053   \n",
       "4144    Зубная паста Colgateт бережное отбеливание 100мл          0.900053   \n",
       "29332  Сок Fleur Alpine груша осветленная с 4 мес орг...          0.900020   \n",
       "29312  Сок Fleur Alpine яблоко осветленное с 4 мес ор...          0.900020   \n",
       "\n",
       "       RANK  ETALON_ID  CANDIDATE_ID  \n",
       "8023      2        800           803  \n",
       "7994      1        803           800  \n",
       "8803      2        882           881  \n",
       "31451     2       3146          3147  \n",
       "31641     2       3168          3166  \n",
       "...     ...        ...           ...  \n",
       "4124      5        410           412  \n",
       "4094      5        410           409  \n",
       "4144      5        410           414  \n",
       "29332     2       2933          2935  \n",
       "29312     2       2935          2933  \n",
       "\n",
       "[1154 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_top_full[final_top_full['SIMILARITY_SCORE']>0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_top_full.to_csv('final_top.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# приведем вывод к виду, требуемому в задании\n",
    "\n",
    "возьмем порог похожести для объединения в кластеры, но такой аутпут не самый информативный с точки зрения работы алгоритма, для изучения алгоритма лучше смотреть на final_top_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRESHOLD  = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(lsts):\n",
    "    sets = [set(lst) for lst in lsts if lst]\n",
    "    merged = True\n",
    "    while merged:\n",
    "        merged = False\n",
    "        results = []\n",
    "        while sets:\n",
    "            common, rest = sets[0], sets[1:]\n",
    "            sets = []\n",
    "            for x in rest:\n",
    "                if x.isdisjoint(common):\n",
    "                    sets.append(x)\n",
    "                else:\n",
    "                    merged = True\n",
    "                    common |= x\n",
    "            results.append(common)\n",
    "        sets = results\n",
    "    return sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = final_top_full.loc[final_top_full['SIMILARITY_SCORE']>TRESHOLD, ['ETALON_ID', 'CANDIDATE_ID']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_clusters = set(final_top_full[final_top_full['SIMILARITY_SCORE']>TRESHOLD]['ETALON_ID']).union(\n",
    "set(final_top_full[final_top_full['SIMILARITY_SCORE']>TRESHOLD]['CANDIDATE_ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_clusters = candidates[~candidates['CANDIDATE_ID'].isin(with_clusters)][['CANDIDATE_ID']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = merge(edges)+no_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_texts = []\n",
    "for i in clusters:\n",
    "    clusters_texts.append(candidates[candidates['CANDIDATE_ID'].isin(i)]['CANDIDATE_NAME'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_texts = sorted(clusters_texts, key=lambda x: len(x), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.json', 'w') as f:\n",
    "    json.dump(clusters_texts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2534"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusters_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# посмотрим на названия, которые не попали в кластеры по порогу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CANDIDATE_NAME</th>\n",
       "      <th>ETALON_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34912</th>\n",
       "      <td>Шампанское AOC Champagne Moet&amp;amp Chandon Nect...</td>\n",
       "      <td>Шампанское AOC Champagne Moet&amp;amp Chandon Brut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13004</th>\n",
       "      <td>Водка Пять озер Премиум 0,5л Россия</td>\n",
       "      <td>Водка ПЯТЬ ОЗЕР Премиум, 0,5л</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13014</th>\n",
       "      <td>Водка ПЯТЬ ОЗЕР Премиум, 0,5л</td>\n",
       "      <td>Водка Пять озер Премиум 0,5л Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19004</th>\n",
       "      <td>Коньяк Remy Martin XO в п/у 0,35л Франция</td>\n",
       "      <td>Коньяк REMY MARTIN XO, 0,35л</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19024</th>\n",
       "      <td>Коньяк REMY MARTIN XO, 0,35л</td>\n",
       "      <td>Коньяк Remy Martin XO в п/у 0,35л Франция</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11114</th>\n",
       "      <td>Газированный напиток COCA-COLA, 2л</td>\n",
       "      <td>Напиток Coca-Cola 2л</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24087</th>\n",
       "      <td>Пивной напиток Corona Extra светлое ст/б 0,355...</td>\n",
       "      <td>Пивной напиток светлое CORONA Extra лагер стек...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24077</th>\n",
       "      <td>Пивной напиток светлое CORONA Extra лагер стек...</td>\n",
       "      <td>Пивной напиток Corona Extra светлое ст/б 0,355...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4391</th>\n",
       "      <td>Перчатки Paclan латексные размер М 10 шт</td>\n",
       "      <td>Перчатки Paclan латексные М 10шт Китай</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>Перчатки Paclan латексные М 10шт Китай</td>\n",
       "      <td>Перчатки Paclan латексные размер М 10 шт</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          CANDIDATE_NAME  \\\n",
       "34912  Шампанское AOC Champagne Moet&amp Chandon Nect...   \n",
       "13004                Водка Пять озер Премиум 0,5л Россия   \n",
       "13014                      Водка ПЯТЬ ОЗЕР Премиум, 0,5л   \n",
       "19004          Коньяк Remy Martin XO в п/у 0,35л Франция   \n",
       "19024                       Коньяк REMY MARTIN XO, 0,35л   \n",
       "...                                                  ...   \n",
       "11114                 Газированный напиток COCA-COLA, 2л   \n",
       "24087  Пивной напиток Corona Extra светлое ст/б 0,355...   \n",
       "24077  Пивной напиток светлое CORONA Extra лагер стек...   \n",
       "4391            Перчатки Paclan латексные размер М 10 шт   \n",
       "4381              Перчатки Paclan латексные М 10шт Китай   \n",
       "\n",
       "                                             ETALON_NAME  \n",
       "34912  Шампанское AOC Champagne Moet&amp Chandon Brut...  \n",
       "13004                      Водка ПЯТЬ ОЗЕР Премиум, 0,5л  \n",
       "13014                Водка Пять озер Премиум 0,5л Россия  \n",
       "19004                       Коньяк REMY MARTIN XO, 0,35л  \n",
       "19024          Коньяк Remy Martin XO в п/у 0,35л Франция  \n",
       "...                                                  ...  \n",
       "11114                               Напиток Coca-Cola 2л  \n",
       "24087  Пивной напиток светлое CORONA Extra лагер стек...  \n",
       "24077  Пивной напиток Corona Extra светлое ст/б 0,355...  \n",
       "4391              Перчатки Paclan латексные М 10шт Китай  \n",
       "4381            Перчатки Paclan латексные размер М 10 шт  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_top_full[(final_top_full['CANDIDATE_ID'].isin(np.array(no_clusters).squeeze()))\n",
    "              &(final_top_full.RANK<=2)\n",
    "              ][['CANDIDATE_NAME', 'ETALON_NAME']].head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывод\n",
    "\n",
    "Алгоритм разработан для полу-автоматического поиска дубликатов, на кластеры смотреть особого смысла нет, т.к. есть дополнительные штрафы на несовпадение цифр(граммовок/объемов) и т.п.\n",
    "\n",
    "лучше смотреть на топ совпадений для каждого кандидата, таким образом и предполагается использование этого инструмента: человек просматривает на топ для каждого нового наименования и выбирает наиболее подходящее, либо добавляет его в список эталонов\n",
    "\n",
    "Алгоритм имеет возможность работать по батчам и параллельно, для лучшей масштабируемости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## возможные улучшения\n",
    "\n",
    "необходимо заводить производителей и страну производителя как отдельный признак, и при поступлении новых наименований заполнять соответствующим образом базу (заполняя необходимые поля)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
